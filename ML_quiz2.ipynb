{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zebu_kSFmFzd"
      },
      "source": [
        "# Data and Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvJWBqhnimOf",
        "outputId": "ec3401e3-355a-49bf-c65a-e772743d89b7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Direktori data training\n",
        "DATADIR = \"/content/drive/MyDrive/dataset/KTP & KTM\"\n",
        "training_data = []\n",
        "width, height = 100, 100\n",
        "\n",
        "# List of characters to include in the dataset (A-Z and 0-9)\n",
        "characters = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "# Looping semua image data training untuk diubah menjadi array\n",
        "for char_name in characters:\n",
        "    path = os.path.join(DATADIR, char_name)\n",
        "    class_name = char_name\n",
        "\n",
        "    for img in tqdm.tqdm(os.listdir(path)):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(DATADIR, char_name, img), cv2.IMREAD_COLOR)\n",
        "\n",
        "            # Konversi gambar ke grayscale\n",
        "            gray_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Tambahkan proses tresholding\n",
        "            _, threshold_array = cv2.threshold(gray_array, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            # Tambahkan proses dilasi\n",
        "            dilated_array = cv2.dilate(threshold_array, (5, 5), iterations=1)\n",
        "\n",
        "            # Tambahkan proses erosi\n",
        "            eroded_array = cv2.erode(dilated_array, (5, 5), iterations=1)\n",
        "\n",
        "            new_array = cv2.resize(eroded_array, (width, height))\n",
        "            training_data.append([new_array, class_name])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for feature, label in training_data:\n",
        "    X.append(feature)\n",
        "    Y.append(label)\n",
        "\n",
        "# Encode string labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "Y_encoded = label_encoder.fit_transform(Y)\n",
        "\n",
        "# Save the label encoder\n",
        "np.save('label_encoder.npy', label_encoder.classes_)\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "Y_one_hot = to_categorical(Y_encoded)\n",
        "\n",
        "X = np.array(X).reshape(-1, width, height, 1)  # Grayscale images have 1 channel\n",
        "\n",
        "# Tulis ke file pickle\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"Y.pickle\", \"wb\")\n",
        "pickle.dump(Y_one_hot, pickle_out)\n",
        "pickle_out.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKuoqsW5kJc4",
        "outputId": "1c38538a-3370-4f20-ea76-3ae8f044f91e"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load file pickle\n",
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Y.pickle\", \"rb\")\n",
        "Y = pickle.load(pickle_in)\n",
        "\n",
        "# Assume Y is already in one-hot encoded format\n",
        "Y_one_hot = np.array(Y)\n",
        "\n",
        "X = X / 255.0\n",
        "width, height = 100, 100\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(width, height, 1))  # Grayscale images have 1 channel\n",
        "\n",
        "conv_layer = ZeroPadding2D(padding=(2, 2))(inputs)\n",
        "conv_layer = Conv2D(16, (5, 5), strides=(1, 1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
        "\n",
        "flaten = Flatten()(conv_layer)\n",
        "fc_layer = Dense(256, activation='relu')(flaten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "\n",
        "# Output layer\n",
        "num_classes = Y_one_hot.shape[1]\n",
        "outputs = Dense(num_classes, activation='softmax')(fc_layer)\n",
        "\n",
        "adam = Adam(lr=0.0001)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, Y_one_hot, epochs=20, verbose=1)\n",
        "model.save('anpr_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fA7sxufmMtq"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "5B0GuCkuqxKW",
        "outputId": "e580fb50-a50b-4f4b-d05d-9cd7432a2a86"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('anpr_model.h5')  # Change the model filename if necessary\n",
        "\n",
        "# Assuming label_encoder.npy is present in the working directory\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.load('label_encoder.npy', allow_pickle=True)\n",
        "\n",
        "# Load a new image for prediction\n",
        "new_image_path = \"/content/test/Screenshot 2023-12-16 at 19.37.33.png\"\n",
        "image = cv2.imread(new_image_path)\n",
        "img_array = cv2.imread(new_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Apply image processing (thresholding, dilasi, erosi, etc.)\n",
        "# Contoh: Thresholding\n",
        "_, thresh = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Contoh: Dilasi\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "# Contoh: Erosi\n",
        "erosion = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "# Resize and normalize the processed image\n",
        "processed_array = cv2.resize(erosion, (width, height))\n",
        "processed_array = np.array(processed_array).reshape(-1, width, height, 1)\n",
        "processed_array = processed_array / 255.0\n",
        "\n",
        "# Display the processed image\n",
        "cv2_imshow(processed_array.squeeze() * 255)  # Scaled back to 0-255 for display\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(processed_array)\n",
        "\n",
        "# Decode the prediction back to the original label\n",
        "predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "print(\"Predicted label: {}\".format(predicted_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z55IOwAvyswM"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your zip file\n",
        "zip_file_path = '/content/Predik.zip'\n",
        "\n",
        "# Use the !unzip command to extract the contents\n",
        "!unzip \"$zip_file_path\" -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7WrgrFwmQMV"
      },
      "source": [
        "# Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sgDYayLG0XKl",
        "outputId": "0a042f07-313a-4be1-96ec-a01a15353e59"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load gambar\n",
        "img = cv2.imread('/content/drive/MyDrive/dataset (1)/images/3C_2141720049_5 - Tri Jagad Ariyani.jpg')  # Replace with the actual image filename and path\n",
        "\n",
        "# Koordinat untuk memotong gambar\n",
        "coordinates = [(1500, 800), (1500, 1500), (3100, 1500), (3100, 800)]\n",
        "\n",
        "# Konversi koordinat ke format array numpy\n",
        "pts = np.array(coordinates, np.int32)\n",
        "pts = pts.reshape((-1, 1, 2))\n",
        "\n",
        "# Memotong gambar menggunakan poligon yang ditentukan oleh koordinat\n",
        "mask = np.zeros_like(img)\n",
        "cv2.fillPoly(mask, [pts], (255, 255, 255))\n",
        "result = cv2.bitwise_and(img, mask)\n",
        "\n",
        "# Mendapatkan koordinat batas hasil crop\n",
        "x, y, w, h = cv2.boundingRect(np.array(coordinates))\n",
        "\n",
        "# Crop gambar hasil crop dengan ukuran asli sebelum crop\n",
        "cropped_result = result[y:y+h, x:x+w]\n",
        "cropped_result2 = result[y:y+h, x:x+w]\n",
        "\n",
        "# Menampilkan gambar hasil crop dengan ukuran asli\n",
        "cv2_imshow(cv2.cvtColor(cropped_result, cv2.COLOR_BGR2RGB))\n",
        "cv2_imshow(cv2.cvtColor(cropped_result, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "# Apply thresholding\n",
        "ret, bw = cv2.threshold(cv2.cvtColor(cropped_result, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "# Show the thresholded image\n",
        "cv2_imshow(bw)\n",
        "\n",
        "# # Define the structuring element for dilation\n",
        "# kernel = np.ones((3, 3), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "# # Apply dilation\n",
        "# dilation = cv2.dilate(bw, kernel, iterations=2)\n",
        "\n",
        "# # Show the dilated image\n",
        "# cv2_imshow(dilation)\n",
        "\n",
        "# Invert image since we trained our model with a black background\n",
        "inversion = 255 - bw\n",
        "# Define the structuring element for dilation\n",
        "kernel = np.ones((2, 2), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "# Apply dilation\n",
        "dilation = cv2.dilate(inversion, kernel, iterations=2)\n",
        "\n",
        "# Show the dilated image\n",
        "cv2_imshow(dilation)\n",
        "\n",
        "kernel = np.ones((4, 4), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "# Apply dilation\n",
        "erode = cv2.erode(dilation, kernel, iterations=2)\n",
        "\n",
        "# Check\n",
        "cv2_imshow(erode)\n",
        "\n",
        "# Create a directory to save individual character images\n",
        "save_dir = '/content/character_images/'  # Specify the directory path\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define function for contour detection\n",
        "def find_contours(img):\n",
        "    conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    conts = imutils.grab_contours(conts)\n",
        "    conts = sorted(conts, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    return conts\n",
        "\n",
        "conts = find_contours(erode.copy())\n",
        "\n",
        "# Define margin size\n",
        "margin = 5  # Adjust according to your requirements\n",
        "\n",
        "# Counter for saving bounding box images\n",
        "bbox_count = 0\n",
        "\n",
        "for c in conts:\n",
        "    (x, y, w, h) = cv2.boundingRect(c)  # find bounding box based on contour\n",
        "\n",
        "    # Expand bounding box with margin\n",
        "    x -= margin\n",
        "    y -= margin\n",
        "    w += 2 * margin\n",
        "    h += 2 * margin\n",
        "\n",
        "    # Ensure the expanded bounding box is within the image boundaries\n",
        "    x = max(0, x)\n",
        "    y = max(0, y)\n",
        "    w = min(cropped_result.shape[1] - 1 - x, w)\n",
        "    h = min(cropped_result.shape[0] - 1 - y, h)\n",
        "\n",
        "    roi = cropped_result[y:y + h, x:x + w]  # get region of interest for char\n",
        "\n",
        "    # Save individual bounding box image\n",
        "    bbox_filename = os.path.join(save_dir, f\"bbox_{bbox_count}.png\")\n",
        "    cv2.imwrite(bbox_filename, roi)\n",
        "\n",
        "    # Increment the bounding box count\n",
        "    bbox_count += 1\n",
        "\n",
        "# Show bounding box on the original image\n",
        "cv2.drawContours(cropped_result, conts, -1, (255, 0, 0), 2)\n",
        "cv2_imshow(cropped_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QonV9uKFCt1x",
        "outputId": "f7efa3aa-9176-4fb6-dac4-9730e110de16"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('anpr_model.h5')  # Change the model filename if necessary\n",
        "\n",
        "# Assuming label_encoder.npy is present in the working directory\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.load('label_encoder.npy', allow_pickle=True)\n",
        "\n",
        "# Directory containing images for prediction\n",
        "folder_path = \"/content/character_images\"  # Change the folder path accordingly\n",
        "\n",
        "# Process each image in the folder\n",
        "for img_filename in os.listdir(folder_path):\n",
        "    # Load an image from the folder\n",
        "    img_path = os.path.join(folder_path, img_filename)\n",
        "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply image processing (thresholding, dilasi, erosi, etc.)\n",
        "    # Contoh: Thresholding\n",
        "    _, thresh = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Contoh: Dilasi\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    # Contoh: Erosi\n",
        "    erosion = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "   # Resize and normalize the processed image\n",
        "    processed_array = cv2.resize(erosion, (100, 100))  # Resize to match the model's input shape\n",
        "    processed_array = np.array(processed_array).reshape(-1, 100, 100, 1)\n",
        "    processed_array = processed_array / 255.0\n",
        "\n",
        "    # Display the processed image (optional)\n",
        "    cv2_imshow(processed_array.squeeze() * 255)  # Scaled back to 0-255 for display\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_array)\n",
        "\n",
        "    # Decode the prediction back to the original label\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "    print(\"Predicted label for {}: {}\".format(img_filename, predicted_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "426ze7cR4vec",
        "outputId": "164084cf-0c36-4130-d385-9c198a44f73e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('anpr_model.h5')  # Change the model filename if necessary\n",
        "\n",
        "# Assuming label_encoder.npy is present in the working directory\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.load('label_encoder.npy', allow_pickle=True)\n",
        "\n",
        "# Create a directory to save individual character images\n",
        "save_dir = '/content/character_images/'  # Specify the directory path\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define function for contour detection\n",
        "def find_contours(img):\n",
        "    conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    conts = imutils.grab_contours(conts)\n",
        "    conts = sorted(conts, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    return conts\n",
        "\n",
        "conts = find_contours(erode.copy())\n",
        "\n",
        "# Define margin size\n",
        "margin = 5  # Adjust according to your requirements\n",
        "\n",
        "# Counter for saving individual character images\n",
        "char_count = 0\n",
        "\n",
        "for c in conts:\n",
        "    (x, y, w, h) = cv2.boundingRect(c)  # find bounding box based on contour\n",
        "\n",
        "    # Expand bounding box with margin\n",
        "    x -= margin\n",
        "    y -= margin\n",
        "    w += 2 * margin\n",
        "    h += 2 * margin\n",
        "\n",
        "    # Ensure the expanded bounding box is within the image boundaries\n",
        "    x = max(0, x)\n",
        "    y = max(0, y)\n",
        "    w = min(cropped_result2.shape[1] - 1 - x, w)\n",
        "    h = min(cropped_result2.shape[0] - 1 - y, h)\n",
        "\n",
        "    roi = cropped_result[y:y + h, x:x + w]  # get region of interest for char\n",
        "\n",
        "    # Save individual character image\n",
        "    char_filename = os.path.join(save_dir, f\"char_{char_count}.png\")\n",
        "    cv2.imwrite(char_filename, roi)\n",
        "\n",
        "    # Increment the character count\n",
        "    char_count += 1\n",
        "\n",
        "    # Convert the character image to grayscale\n",
        "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Resize and normalize the processed image\n",
        "    processed_array = cv2.resize(roi_gray, (100, 100))  # Resize to match the model's input shape\n",
        "    processed_array = np.array(processed_array).reshape(-1, 100, 100, 1)  # Convert to 1 channel\n",
        "    processed_array = processed_array / 255.0\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_array)\n",
        "\n",
        "    # Decode the prediction back to the original label\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "    # Draw bounding box on the original image with predicted label\n",
        "    cv2.putText(cropped_result, predicted_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    # cv2.rectangle(cropped_result2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# Show bounding box on the original image with predicted labels\n",
        "cv2_imshow(cropped_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqR7u8oSl0M7"
      },
      "source": [
        "# Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSPYoFICeIgF"
      },
      "source": [
        "Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utYN57S2etTC"
      },
      "outputs": [],
      "source": [
        "def Pred_img(img_path) :\n",
        "    # Load gambar\n",
        "      img = cv2.imread(img_path)  # Replace with the actual image filename and path\n",
        "\n",
        "      # Apply thresholding\n",
        "      ret, bw = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "      # Show the thresholded image\n",
        "      cv2_imshow(bw)\n",
        "\n",
        "      # # Define the structuring element for dilation\n",
        "      # kernel = np.ones((3, 3), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "      # # Apply dilation\n",
        "      # dilation = cv2.dilate(bw, kernel, iterations=2)\n",
        "\n",
        "      # # Show the dilated image\n",
        "      # cv2_imshow(dilation)\n",
        "\n",
        "      # Invert image since we trained our model with a black background\n",
        "      inversion = 255 - bw\n",
        "      # Define the structuring element for dilation\n",
        "      kernel = np.ones((2, 2), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "      # Apply dilation\n",
        "      dilation = cv2.dilate(inversion, kernel, iterations=2)\n",
        "\n",
        "      # Show the dilated image\n",
        "      cv2_imshow(dilation)\n",
        "\n",
        "      kernel = np.ones((4, 4), np.uint8)  # You can adjust the size as needed\n",
        "\n",
        "      # Apply dilation\n",
        "      erode = cv2.erode(dilation, kernel, iterations=2)\n",
        "\n",
        "      # Check\n",
        "      cv2_imshow(erode)\n",
        "\n",
        "      # Load the trained model\n",
        "      model = load_model('anpr_model.h5')  # Change the model filename if necessary\n",
        "\n",
        "      # Assuming label_encoder.npy is present in the working directory\n",
        "      label_encoder = LabelEncoder()\n",
        "      label_encoder.classes_ = np.load('label_encoder.npy', allow_pickle=True)\n",
        "\n",
        "\n",
        "      # Define function for contour detection\n",
        "      def find_contours(img):\n",
        "          conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          conts = imutils.grab_contours(conts)\n",
        "          conts = sorted(conts, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "          return conts\n",
        "\n",
        "      conts = find_contours(erode.copy())\n",
        "\n",
        "      # Define margin size\n",
        "      margin = 5  # Adjust according to your requirements\n",
        "\n",
        "      # Counter for saving individual character images\n",
        "      char_count = 0\n",
        "\n",
        "      for c in conts:\n",
        "          (x, y, w, h) = cv2.boundingRect(c)  # find bounding box based on contour\n",
        "\n",
        "          # Expand bounding box with margin\n",
        "          x -= margin\n",
        "          y -= margin\n",
        "          w += 2 * margin\n",
        "          h += 2 * margin\n",
        "\n",
        "          # Ensure the expanded bounding box is within the image boundaries\n",
        "          x = max(0, x)\n",
        "          y = max(0, y)\n",
        "          w = min(img.shape[1] - 1 - x, w)\n",
        "          h = min(img.shape[0] - 1 - y, h)\n",
        "\n",
        "          roi = img[y:y + h, x:x + w]  # get region of interest for char\n",
        "\n",
        "          # Increment the character count\n",
        "          char_count += 1\n",
        "\n",
        "          # Check if roi is not empty\n",
        "          if not roi.size == 0:\n",
        "              # Convert the character image to grayscale\n",
        "              roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "              # Resize and normalize the processed image\n",
        "              processed_array = cv2.resize(roi_gray, (100, 100))  # Resize to match the model's input shape\n",
        "              processed_array = np.array(processed_array).reshape(-1, 100, 100, 1)  # Convert to 1 channel\n",
        "              processed_array = processed_array / 255.0\n",
        "\n",
        "              # Make prediction\n",
        "              prediction = model.predict(processed_array)\n",
        "\n",
        "              # Decode the prediction back to the original label\n",
        "              predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "              # Draw bounding box on the original image with predicted label\n",
        "              cv2.putText(img, predicted_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "              cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Draw bounding box\n",
        "\n",
        "      # Show bounding box on the original image with predicted labels\n",
        "      cv2_imshow(img)\n",
        "      return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ya3_e3otexsF",
        "outputId": "5e4c787b-f833-4c6b-fb1b-87aa7fa83b51"
      },
      "outputs": [],
      "source": [
        "image1 = Pred_img(\"/content/drive/MyDrive/dataset (1)/images/3C_2141720049_5 - Tri Jagad Ariyani.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NewuOtPCjYsp"
      },
      "source": [
        "Function2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQhB60V7jaaj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdphBClS2jkN"
      },
      "source": [
        "# Version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4kdV9Jbv2mxU",
        "outputId": "2d14a86b-3e8c-484e-f3bf-e32ba8c7d967"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import os\n",
        "from imutils.contours import sort_contours\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Load gambar\n",
        "img = cv2.imread('/content/drive/MyDrive/dataset (1)/images/3C_2141720049_5 - Tri Jagad Ariyani.jpg')  # Replace with the actual image filename and path\n",
        "\n",
        "# Koordinat untuk memotong gambar\n",
        "coordinates = [(1500, 800), (1500, 1500), (3100, 1500), (3100, 800)]\n",
        "\n",
        "# Konversi koordinat ke format array numpy\n",
        "pts = np.array(coordinates, np.int32)\n",
        "pts = pts.reshape((-1, 1, 2))\n",
        "\n",
        "# Memotong gambar menggunakan poligon yang ditentukan oleh koordinat\n",
        "mask = np.zeros_like(img)\n",
        "cv2.fillPoly(mask, [pts], (255, 255, 255))\n",
        "result = cv2.bitwise_and(img, mask)\n",
        "\n",
        "# Mendapatkan koordinat batas hasil crop\n",
        "x, y, w, h = cv2.boundingRect(np.array(coordinates))\n",
        "\n",
        "# Crop gambar hasil crop dengan ukuran asli sebelum crop\n",
        "cropped_result = result[y:y+h, x:x+w]\n",
        "\n",
        "# Menampilkan gambar hasil crop dengan ukuran asli\n",
        "cv2_imshow(cv2.cvtColor(cropped_result, cv2.COLOR_BGR2RGB))\n",
        "cv2_imshow(cv2.cvtColor(cropped_result, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "gray = cv2.cvtColor(cropped_result, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "dilated = cv2.dilate(blur, np.ones((3,3)))\n",
        "adaptive = cv2.adaptiveThreshold(dilated, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 1)\n",
        "invertion = 255 - adaptive\n",
        "erode = cv2.erode(invertion, np.ones((3,3)))\n",
        "dilated = cv2.dilate(erode, np.ones((2,2)))\n",
        "\n",
        "# Check\n",
        "cv2_imshow(dilated)\n",
        "\n",
        "# Define function for contour detection\n",
        "def find_contours(img):\n",
        "  conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  conts = imutils.grab_contours(conts)\n",
        "  conts = sort_contours(conts, method='left-to-right')[0]\n",
        "\n",
        "  return conts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUqJ0So734yk"
      },
      "outputs": [],
      "source": [
        "conts = find_contours(dilated.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tGldc0v-3726",
        "outputId": "b240acfb-524c-4ff4-941f-ae9fd43c0d7d"
      },
      "outputs": [],
      "source": [
        "# Get the char based on contour with margin in bounding box\n",
        "\n",
        "# Setup min/max width/height for char\n",
        "min_w, max_w = 30, 160\n",
        "min_h, max_h = 34, 140\n",
        "margin = 5  # Set the margin value\n",
        "\n",
        "img_copy = cropped_result.copy()  # original image for plotting contour result\n",
        "filtered_conts = []\n",
        "\n",
        "# Create a directory to save individual character images\n",
        "save_dir = '/content/character_images2/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for c in conts:\n",
        "    (x, y, w, h) = cv2.boundingRect(c)  # find bounding box based on contour\n",
        "\n",
        "    # Expand bounding box with margin\n",
        "    x -= margin\n",
        "    y -= margin\n",
        "    w += 2 * margin\n",
        "    h += 2 * margin\n",
        "\n",
        "    # Ensure the expanded bounding box is within the image boundaries\n",
        "    x = max(0, x)\n",
        "    y = max(0, y)\n",
        "    w = min(gray.shape[1] - 1 - x, w)\n",
        "    h = min(gray.shape[0] - 1 - y, h)\n",
        "\n",
        "    if (w >= min_w and w <= max_w) and (h >= min_h and h <= max_h):  # if pixel follows this rule, it is considered as a char\n",
        "        filtered_conts.append(c)\n",
        "        roi = gray[y:y+h, x:x+w]  # get region of interest for char\n",
        "        thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        cv2_imshow(thresh)  # check\n",
        "\n",
        "        # Save individual character image\n",
        "        char_filename = os.path.join(save_dir, f\"char_{len(filtered_conts)}.png\")\n",
        "        cv2.imwrite(char_filename, roi)  # Save the character image instead of the bounding box\n",
        "\n",
        "        # Build bounding box on the original image (for visualization purposes)\n",
        "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), (255, 0, 0), 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9QIwTXS4vrV"
      },
      "outputs": [],
      "source": [
        "# Define the functions\n",
        "def extract_roi(img, margin=2):\n",
        "    roi = img[margin:-margin, margin:-margin]\n",
        "    return roi\n",
        "\n",
        "def thresholding(img):\n",
        "    thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "    return thresh\n",
        "\n",
        "def resize_img(img):\n",
        "    if img is None:\n",
        "        # Handle the case where thresholding did not produce a valid result\n",
        "        return None\n",
        "\n",
        "    resized = cv2.resize(img, (100, 100))  # Sesuaikan dengan dimensi yang diharapkan oleh model\n",
        "    resized = np.expand_dims(resized, axis=-1)\n",
        "    resized = np.expand_dims(resized, axis=0)\n",
        "\n",
        "    return resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "AGHwq2RP4wUs",
        "outputId": "5823ed6e-b83a-4de7-84b1-1794460640ce"
      },
      "outputs": [],
      "source": [
        "# Demo for enlarge\n",
        "(x, y, w, h) = cv2.boundingRect(filtered_conts[2])\n",
        "test_image = thresholding(gray[y:y+h, x:x+w])\n",
        "\n",
        "# show original test image\n",
        "cv2_imshow(test_image)\n",
        "\n",
        "# Show enlarge test image\n",
        "cv2_imshow(cv2.resize(test_image, (28,28)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrABaSgP40us"
      },
      "outputs": [],
      "source": [
        "def normalization(img):\n",
        "    img = img.astype('float32') / 255.0  # Convert to floating point and scale to [0, 1]\n",
        "    img = np.expand_dims(img, axis=-1)  # Add depth\n",
        "\n",
        "    # Perform any additional normalization or preprocessing steps if needed\n",
        "\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jml9s59xFe3C"
      },
      "outputs": [],
      "source": [
        "# Create a directory to save processed character images\n",
        "processed_dir = '/content/processed_character_images/'\n",
        "os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "char_dir = '/content/character_images2'\n",
        "\n",
        "# Process each character image in the input directory\n",
        "for char_filename in os.listdir(char_dir):\n",
        "    char_path = os.path.join(char_dir, char_filename)\n",
        "    char_img = cv2.imread(char_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Extract the region of interest\n",
        "    roi = extract_roi(char_img)\n",
        "\n",
        "    # Apply thresholding\n",
        "    thresh = thresholding(roi)\n",
        "\n",
        "    # Save the processed character image\n",
        "    output_filename = os.path.join(processed_dir, f\"processed_{char_filename}\")\n",
        "    cv2.imwrite(output_filename, thresh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZXDOCW5493R"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/anpr_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2N9pejmBdil",
        "outputId": "f257e4f4-91a7-4558-9b83-8ede112a23ad"
      },
      "outputs": [],
      "source": [
        "digits = '0123456789'\n",
        "letters = 'ABCDEFGHIJKLMNOPQRSTUVWZYZabcdefghijklmnopqrstuvwxyz'\n",
        "char_list = digits + letters\n",
        "char_list = [ch for ch in char_list]\n",
        "\n",
        "print(char_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tEIvzzRTOyow",
        "outputId": "e21bd322-8c8e-4c53-dda4-8b5fe768cad7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('anpr_model.h5')  # Change the model filename if necessary\n",
        "\n",
        "# Assuming label_encoder.npy is present in the working directory\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.load('label_encoder.npy', allow_pickle=True)\n",
        "\n",
        "# Directory containing images for prediction\n",
        "folder_path = \"/content/character_images2\"  # Change the folder path accordingly\n",
        "\n",
        "# Process each image in the folder\n",
        "for img_filename in os.listdir(folder_path):\n",
        "    # Load an image from the folder\n",
        "    img_path = os.path.join(folder_path, img_filename)\n",
        "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply image processing (thresholding, dilasi, erosi, etc.)\n",
        "    # Contoh: Thresholding\n",
        "    _, thresh = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Contoh: Dilasi\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    # Contoh: Erosi\n",
        "    erosion = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "   # Resize and normalize the processed image\n",
        "    processed_array = cv2.resize(erosion, (100, 100))  # Resize to match the model's input shape\n",
        "    processed_array = np.array(processed_array).reshape(-1, 100, 100, 1)\n",
        "    processed_array = processed_array / 255.0\n",
        "\n",
        "    # Display the processed image (optional)\n",
        "    cv2_imshow(processed_array.squeeze() * 255)  # Scaled back to 0-255 for display\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_array)\n",
        "\n",
        "    # Decode the prediction back to the original label\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "    print(\"Predicted label for {}: {}\".format(img_filename, predicted_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y4W-gOe1j6Mu",
        "outputId": "f86e27f7-1d37-482a-d682-951213a7ae37"
      },
      "outputs": [],
      "source": [
        "# Display the original image\n",
        "cv2_imshow(img_copy)\n",
        "\n",
        "# Process each image in the folder\n",
        "for img_filename in os.listdir(folder_path):\n",
        "    # Load an image from the folder\n",
        "    img_path = os.path.join(folder_path, img_filename)\n",
        "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply image processing (thresholding, dilasi, erosi, etc.)\n",
        "    # Contoh: Thresholding\n",
        "    _, thresh = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Contoh: Dilasi\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    # Contoh: Erosi\n",
        "    erosion = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "    # Resize and normalize the processed image\n",
        "    processed_array = cv2.resize(erosion, (100, 100))  # Resize to match the model's input shape\n",
        "    processed_array = np.array(processed_array).reshape(-1, 100, 100, 1)\n",
        "    processed_array = processed_array / 255.0\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_array)\n",
        "\n",
        "    # Decode the prediction back to the original label\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "    # Ensure count is within the range of filtered_conts\n",
        "    count = int(img_filename.split('_')[1].split('.')[0])\n",
        "    if count < len(filtered_conts):\n",
        "        # Get the bounding box coordinates from filtered_conts\n",
        "        x, y, w, h = cv2.boundingRect(filtered_conts[count])\n",
        "\n",
        "        # Draw bounding box and label on the original image\n",
        "        color = (0, 255, 0)  # Green color for bounding box\n",
        "        thickness = 2\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), color, thickness)\n",
        "\n",
        "        # Draw label\n",
        "        label_position = (x, y - 10)  # Above the bounding box\n",
        "        cv2.putText(img_copy, predicted_label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness)\n",
        "\n",
        "# Display the result\n",
        "cv2_imshow(img_copy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
